{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1NPekVDEkTBW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PfLEHPDkTBX"
      },
      "source": [
        "# Data Visulaisation and EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DjN1xKM_kTBX",
        "outputId": "2bde7e1d-d9b8-4ca6-83ae-bb5d003825e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-8e7e86be3df0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data.csv'"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv(\"Data.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4Y_FGa0kTBY"
      },
      "outputs": [],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFhLGcDzkTBY"
      },
      "outputs": [],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfGGy5LnkTBY"
      },
      "source": [
        "There is non-availability of data related to trades for every Stock before 2012. We have all values available for all stocks after 2012."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Psj_YsOkTBY"
      },
      "outputs": [],
      "source": [
        "data = data[data.Date >= '2012-01-01']\n",
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COpC-sNKkTBZ"
      },
      "source": [
        "No NULL values present henceforth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULJpr7DnkTBZ"
      },
      "outputs": [],
      "source": [
        "Tickers = data[\"Symbol\"].unique().tolist()\n",
        "print(Tickers)\n",
        "print(f\"Total Number of Stocks: {len(Tickers)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EwsB9RjkTBZ"
      },
      "source": [
        "There are stock data of 53 stocks present here. But since we are working on NIFTY_50 data, there should only have been 49 stocks (We dont have data on INFRATEL). There are 53 because name of 4 Tickers got changed between the time period of 2012-2021 hence we are receiving these extra 4 Symbols/Tickers. The changed ones are namely: MUNDRAPORT, UNIPHOS, SESAGOA, SSLT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-AMNE3IkTBZ"
      },
      "source": [
        "MUNDRAPORT and UNIPHOS were changed due to rebranding of the companies and hence data under these tickers can be used as data under their new Tickers (ADANIPORT and UPL).\n",
        "\n",
        "In cases like SESAGOA and SSLT, where the companies merged and became part of Vedanta Limited (VEDL), the business fundamentals might have changed. This means that historical data before the merger might not fully represent the current company's operations. So, data under these tickers should be ignored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8SHaU3ckTBZ"
      },
      "outputs": [],
      "source": [
        "symbol_mapping = {\n",
        "    'MUNDRAPORT': 'ADANIPORTS',\n",
        "    'UNIPHOS': 'UPL',\n",
        "}\n",
        "data['Symbol'] = data['Symbol'].replace(symbol_mapping)\n",
        "data = data[~data[\"Symbol\"].isin(['SESAGOA', 'SSLT'])]\n",
        "\n",
        "Tickers = data[\"Symbol\"].unique().tolist()\n",
        "print(Tickers)\n",
        "print(f\"Total Number of Stocks: {len(Tickers)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rifGiwIdkTBZ"
      },
      "outputs": [],
      "source": [
        "# Convert 'Date' column to datetime format\n",
        "data['Date'] = pd.to_datetime(data['Date'], dayfirst=True, format='mixed')\n",
        "data.index = data.Date\n",
        "data = data.drop(columns=[\"Date\"], axis=1)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NU_gPOeUkTBa"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "# Number of symbols\n",
        "num_symbols = len(Tickers)\n",
        "\n",
        "# Set up the grid layout (3 columns)\n",
        "rows = math.ceil(num_symbols / 6)\n",
        "cols = 6\n",
        "\n",
        "# Create a figure with subplots\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(36, 4 * rows))\n",
        "fig.suptitle('Closing Prices for Different Symbols', fontsize=20)\n",
        "\n",
        "# Flatten axes array for easy indexing\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Plot closing prices for each symbol\n",
        "for i, symbol in enumerate(Tickers):\n",
        "    # Filter data for the current symbol\n",
        "    symbol_data = data[data[\"Symbol\"] == symbol]\n",
        "\n",
        "    # Plot on the corresponding subplot\n",
        "    axes[i].plot(symbol_data.index.tolist(), symbol_data[\"Close\"], color='blue', linestyle='-', linewidth=1)\n",
        "\n",
        "    # Adding titles and labels to the current subplot\n",
        "    axes[i].set_title(f'{symbol} Closing Prices', fontsize=10)\n",
        "    axes[i].set_xlabel('Date', fontsize=8)\n",
        "    axes[i].set_ylabel('Closing Price (INR)', fontsize=8)\n",
        "\n",
        "    # Rotate the x-axis labels for better readability\n",
        "    axes[i].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # Format the x-axis date labels\n",
        "    axes[i].xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y-%m'))\n",
        "\n",
        "    # Adding gridlines\n",
        "    axes[i].grid(visible=True, linestyle='--', alpha=0.5)\n",
        "\n",
        "# Hide any unused subplots\n",
        "for j in range(i + 1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])  # Leave space for the main title\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6vli-M5kTBa"
      },
      "source": [
        "Here it can be seen that there are trends in stock with a sudden decrease in close price. These happen due to external factors which we are not going to model here. So, we might need to have a different eda/ model for these trends than that of regular trends."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9ZDHco-kTBa"
      },
      "outputs": [],
      "source": [
        "# Initialize dictionaries to store categorized symbols\n",
        "stable_trend = []\n",
        "sudden_changes = []\n",
        "\n",
        "# Categorization thresholds\n",
        "change_threshold = 0.3 # For sudden change detection\n",
        "\n",
        "for symbol in Tickers:\n",
        "    # Get the closing prices for the symbol\n",
        "    symbol_data = data[data[\"Symbol\"] == symbol][\"Close\"].values\n",
        "\n",
        "    # Calculate percentage change\n",
        "    percent_changes = np.diff(symbol_data) / symbol_data[:-1]\n",
        "\n",
        "    # Detect sudden changes\n",
        "    sudden_change_detected = np.any(np.abs(percent_changes) > change_threshold)\n",
        "\n",
        "    # Categorize based on criteria\n",
        "    if sudden_change_detected:\n",
        "        sudden_changes.append(symbol)\n",
        "    else:\n",
        "        stable_trend.append(symbol)\n",
        "\n",
        "# Output results\n",
        "print(\"Stable Trend Symbols:\", stable_trend)\n",
        "print(\"Sudden Change Symbols:\", sudden_changes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ID9OVDnDkTBa"
      },
      "source": [
        "Here, we are going to perform EDA on one symbol of each trend intsead of a different sets of EDA for all Symbols assuming that all other symbols of same group will behave in similar fashion under EDA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0G-8f9mKkTBa"
      },
      "outputs": [],
      "source": [
        "data_adaniports = data[data[\"Symbol\"] == 'ADANIPORTS']\n",
        "data_asianpaints = data[data[\"Symbol\"] == 'ASIANPAINT']\n",
        "\n",
        "print(\"ADANIPOTS:\")\n",
        "display(data_adaniports)\n",
        "print(\"ASIANPAINT:\")\n",
        "display(data_asianpaints)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ADANIPORTS\")\n",
        "display(data_adaniports.info())\n",
        "\n",
        "print(\"ASIANPAINT\")\n",
        "display(data_asianpaints.info())"
      ],
      "metadata": {
        "id": "sjMrlvvxkU8O"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}